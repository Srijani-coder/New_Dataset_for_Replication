{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhls9C3/fRet5dBE62rxzh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srijani-coder/New_Dataset_for_Replication/blob/main/factcheck_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZaQO_z96FTj",
        "outputId": "1fd7daba-c935-4821-b833-51ee808af81f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Collecting requests-html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from requests-html) (2.31.0)\n",
            "Collecting pyquery (from requests-html)\n",
            "  Downloading pyquery-2.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting fake-useragent (from requests-html)\n",
            "  Downloading fake_useragent-1.3.0-py3-none-any.whl (15 kB)\n",
            "Collecting parse (from requests-html)\n",
            "  Downloading parse-1.19.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting bs4 (from requests-html)\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting w3lib (from requests-html)\n",
            "  Downloading w3lib-2.1.2-py3-none-any.whl (21 kB)\n",
            "Collecting pyppeteer>=0.0.14 (from requests-html)\n",
            "  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2021 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (2023.7.22)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (6.8.0)\n",
            "Collecting pyee<9.0.0,>=8.1.0 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.66.1)\n",
            "Collecting urllib3<2.0.0,>=1.25.8 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->requests-html) (4.11.2)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyquery->requests-html) (4.9.3)\n",
            "Collecting cssselect>=1.2.0 (from pyquery->requests-html)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->requests-html) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->requests-html) (3.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->requests-html) (2.5)\n",
            "Building wheels for collected packages: bs4\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1256 sha256=dceed65aa30e845ed521273737f4873d54cc03ddd77c8ff0863faf7bc2c184ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "Successfully built bs4\n",
            "Installing collected packages: pyee, parse, fake-useragent, websockets, w3lib, urllib3, cssselect, pyquery, pyppeteer, bs4, requests-html\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "Successfully installed bs4-0.0.1 cssselect-1.2.0 fake-useragent-1.3.0 parse-1.19.1 pyee-8.2.2 pyppeteer-1.0.2 pyquery-2.0.0 requests-html-0.10.0 urllib3-1.26.18 w3lib-2.1.2 websockets-10.4\n"
          ]
        }
      ],
      "source": [
        "!pip install requests\n",
        "!pip install beautifulsoup4\n",
        "!pip install requests-html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from requests_html import HTMLSession\n",
        "\n",
        "# establish a session\n",
        "session = HTMLSession()\n",
        "\n"
      ],
      "metadata": {
        "id": "YIzf8la4VVGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response_url(url):\n",
        "  root_url = \"https://mediabiasfactcheck.com/?s=\"\n",
        "  sum_url = root_url + url\n",
        "  resp = session.get(sum_url)\n",
        "  return resp"
      ],
      "metadata": {
        "id": "RYPwE40oVXtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "LWQ8w-iFXiVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bias_search_url_tool(url):\n",
        "  response = get_response_url(url)\n",
        "  bias_links = response.html.find(\"a\", containing = \"bias\")\n",
        "  pattern = r\"<Element 'a' href='https://mediabiasfactcheck.com/([^/]+)/' title='([^']+) Bias and Credibility' rel=\\('bookmark',\\)>\"\n",
        "  pattern2 = r\"<Element 'a' href='https://mediabiasfactcheck.com/([^/]+)/' title='([^']+)(?: Bias| Biased)' rel=\\('bookmark',\\)>\"\n",
        "\n",
        "  biasdict = {}\n",
        "  url_bias_dict = {}\n",
        "  biascredict = {}\n",
        "  url_biascred_dict = {}\n",
        "\n",
        "  for x in bias_links:\n",
        "    tex = str(x)\n",
        "    match1 = re.search(pattern,tex)\n",
        "    match2 = re.search(pattern2,tex)\n",
        "    if match2:\n",
        "      # Access the captured groups using match.group(1) and match.group(2)\n",
        "      biasdict = {}\n",
        "      anything = match2.group(1)\n",
        "      url_bias = 'https://mediabiasfactcheck.com/'+anything+'/'\n",
        "      print(url_bias)\n",
        "      anything_title = match2.group(2)\n",
        "      print(f\"Matched 'anything': {anything}\")\n",
        "      print(f\"Matched 'Anything' (title): {anything_title}\")\n",
        "      biasdict = {\"bias\": anything_title}\n",
        "      url_bias_dict = {\"search_bias_url\":url_bias}\n",
        "    elif match1:\n",
        "      biascredict = {}\n",
        "      anything2 = match1.group(1)\n",
        "      url_biascred = 'https://mediabiasfactcheck.com/'+anything2+'/'\n",
        "      print(url_bias)\n",
        "      anything_title2 = match1.group(2)\n",
        "      print(f\"Matched 'anything': {anything2}\")\n",
        "      print(f\"Matched 'Anything' (title): {anything_title2}\")\n",
        "      biascredict = {\"biascred\": anything2}\n",
        "      url_biascred_dict = {\"search_biascred_url\":url_biascred}\n",
        "\n",
        "    url_returned_tobe = []\n",
        "    url_returned_tobe.append(biasdict)\n",
        "    url_returned_tobe.append(url_bias_dict)\n",
        "    url_returned_tobe.append(biascredict)\n",
        "    url_returned_tobe.append(url_biascred_dict)\n",
        "    return {url:url_returned_tobe}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9K9zY80gWsT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "4AvWThZ1jZ0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_detailed_report(url):\n",
        "  get_tools_list = get_bias_search_url_tool(url)\n",
        "  url_bias_dict = get_tools_list[1]\n",
        "  url_biascred_dict = get_tools_list[3]\n",
        "  search_url1 = url_bias_dict[\"search_bias_url\"]\n",
        "  search_url2 = url_biascred_dict[\"search_biascred_url\"]\n",
        "  sep3 = session.get(search_url2)\n",
        "  #Detailed Report\n",
        "  #Bias Rating: RIGHT-CENTER\n",
        "  #Factual Reporting: MIXED\n",
        "  pattern3 = r\"Bias Rating:([^/]+)\"\n",
        "  pattern4 = r\"Factual Reporting:([^/]+)\"\n",
        "  match3 = re.search(pattern3,sep3)\n",
        "  match4 = re.search(pattern4,sep3)\n",
        "  print(match3.group(1))\n",
        "  print(match4.group(1))\n",
        "  list_match3 = match3.group(1).split(\"\\n\")\n",
        "  list_match4 = match4.group(1).split(\"\\n\")\n",
        "  print(list_match3[0])\n",
        "  print(list_match4[0])"
      ],
      "metadata": {
        "id": "GEMjBlOYUXJn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hfH0LO0wrYdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eVxVrbCjrZtu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}